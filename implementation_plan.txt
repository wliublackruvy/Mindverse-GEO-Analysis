Current Verification Focus (per PRD §3 & §4):
1. [F-01] Reconfirm frontend benchmark copy requirement (“该行业平均 AI 推荐率为 25%”) and ensure industry selector displays this exact static wording regardless of industry.
2. [E-02] Expand sensitive keyword detection to cover all user-provided fields (公司全称/产品名称/描述) so any input hit triggers the mandated拦截提示。

Scope (PRD §1.3 & §3):
- In Scope: F-01~F-05 user journey (form fields, progress UX, conversion logic, advice output), F-06 realtime engine + cache, E-01/E-02 exception flows, Section 5 analytics telemetry.
- Out of Scope: Deployment packaging, PDF export pipeline, external marketing automation beyond CTA triggers.

Acceptance Criteria (by PRD IDs):
- F-01: Form fields (company/product/description ≥10 chars/industry/email) are required; industry selection instantly displays "该行业平均 AI 推荐率为 25%" style copy; submission banner conveys real-time Doubao & DeepSeek sourcing.
- F-02: Each platform executes 20 simulations per diagnosis; SOV computed as 推荐次数/20*100%; Discovery/Evaluation prompts match PRD; Doubao (doubao-pro) uses temp 0.4/top_p 0.8; DeepSeek (deepseek-chat) enforces max_tokens 512 & finish_reason validation; token bucket (60 RPM) + 3 retries with 2^n backoff; llm_logs capture task_id/platform/prompt_type/prompt_hash/response_json/latency_ms; competitor extraction present.
- F-03: Console log strings stream pseudo system/analysis lines; charts refresh every 5 runs via snapshots; UI waits show progress.
- F-04: Conversion card matches table logic (modes, thresholds, copies, CTA) and surfaces competitor in growth mode.
- F-05: Always returns 3 tactical advices exactly as specified for low SOV, high negative tags, and detected competitors with placeholders filled from runtime metrics.
- F-06.1~6: Secrets Manager isolates keys, tracks quota/expires; per-task concurrency queue + coverage flags; sanitized prompts remove email/phone/address; unified schema exposes {platform,prompt_type,content[],mentions[],sentiment.score}; raw logs retained, cache hits labeled “(来自缓存，已进入实时重试队列)”; degraded runs fall back to estimation; UI banner communicates data source; offline cache/resend note captured in metrics/logs.
- E-01: After 3 consecutive API failures per platform, silently degrade to industry estimation with grey note "*Based on Industry Estimation*" while keeping other platform alive.
- E-02: Sensitive keywords in input/output halt generation with prescribed popup copy linking到加微信方案.
- Analytics §5: Track funnel (visit, submit, wait, CTA click), industry distribution, and report download/share events.

Constraints:
- Add inline comments tagged with “# PRD: <ID>” for implemented logic.
- Prefer minimal diff, keep async-safe structures; no reliance on external network/migrations.

Implementation Plan (mapped to PRD sections):
1. [F-01/F-06.5] Update frontend form/app.js/index.html to show benchmark copy immediately, append assurance banner post-submit, and ensure CTA flows emit analytics events for visit/submit/wait/cta/report share.
2. [F-02/F-06.2/6] Enhance LLMOrchestrator to run 20 iterations per platform (40 total default), add retry/backoff/token bucket enforcement, extend llm_logs retention metadata, and expose cache/degraded information back to engine with coverage flags.
3. [F-02/F-03] Update engine metrics builder to assume per-platform totals (SOV denominator 20), ensure snapshots refresh every 5 iterations, and include console log text samples; adjust conversion/advice logic alignment (# PRD: F-04/F-05).
4. [F-05] Refactor advice builder to strictly follow three PRD bullet logics (low SOV, high negativity, competitor differentiation) with fallback placeholders.
5. [E-01/E-02] Extend validation + orchestrator to detect sensitive words from both inputs and LLM outputs, raising correct message; ensure 3-strike degradation gracefully switches to industry estimation and logs grey note.
6. [Analytics §5] Expand AnalyticsTracker usage plus frontend instrumentation to capture funnel (visit -> submit -> waiting -> CTA click) and exports for industry distribution/report share events; add tests verifying event sequences.
7. [Testing] Add/extend pytest cases covering new advice strings, analytics emissions, sensitive-output blocking, retry/backoff behavior, frontend? (JS via snapshot) not testable; ensure pytest -q passes.
